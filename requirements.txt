# Core dependencies
langchain>=0.0.267
openai>=1.0.0
faiss-cpu>=1.7.4
peft>=0.5.0
transformers>=4.35.0
datasets>=2.14.0
trl>=0.7.0
sentence-transformers>=2.2.2
torch>=2.0.0
huggingface-hub>=0.17.0

# LLM Providers
tiktoken>=0.5.1  # For OpenAI token counting
anthropic>=0.5.2  # For Anthropic Claude models
requests>=2.31.0  # For API calls to HuggingFace and other services

# Optional local model support
# llama-cpp-python>=0.1.77  # For local model inference with llama.cpp
# vllm>=0.1.4  # For local model inference with vLLM

# Vector stores
qdrant-client>=1.5.0
weaviate-client>=3.25.0
chromadb>=0.4.18

# API and serving
fastapi>=0.104.0
uvicorn>=0.23.0
streamlit>=1.28.0
gradio>=3.50.0

# Logging and tracking
wandb>=0.15.0
mlflow>=2.7.0

# Optional orchestration
prefect>=2.13.0

# Utilities
tqdm>=4.65.0
jsonlines>=3.1.0
python-dotenv>=1.0.0
